# -*- coding: utf-8 -*-
"""Clustering Electricity Usage.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZpWzpR-8w6Y624FxSExl-KkSwXqplrM1

```
# This is formatted as code
```

# Ambil Data API
"""

import requests
import pandas as pd
from datetime import datetime, timedelta
from dateutil import parser
import sys 
import numpy as np # linear algebra
import matplotlib.pyplot as plt # this is used for the plot the graph 
import seaborn as sns # used for plot interactive graph. 
from sklearn.preprocessing import StandardScaler # for normalization
from sklearn.preprocessing import MinMaxScaler
from sklearn import metrics # for the check the error and accuracy of the model
from sklearn.metrics import mean_squared_error,r2_score

def Get_Data():
    base_url = "http://213.190.4.40/iems/iems-api/index.php"
    device_token = "6cc5dc0059d39c5392784721c78d4bb3"
    page = 0
    batas = False
 
    api_data_lisrik = []
    api_data_device = []
    api_data_date = []
    api_data_time = []

 
    while (batas == False) :
      pull = requests.get(base_url + "/public/devices/pull?device_token=" + device_token + "&page=" + str(page)).json()
      page += 1
      if (len(pull["data"])) != 0:
        for i in range(len(pull['data'])): 
          api_data_lisrik.insert(0,float(pull["data"][i]["ep"]))
          api_data_device.insert(0,pull["data"][i]["id_m_devices"])
          api_data_date.insert(0,pull["data"][i]["date"])
          api_data_time.insert(0,pull["data"][i]["time"])
    
      else:  
        batas = True
 
    dataset = pd.DataFrame({'Date': api_data_date, 'Time': api_data_time,'Device': api_data_device, 'Kwh': api_data_lisrik})
    dataset
    return dataset

Data = Get_Data()

Data.to_csv("data_api1.csv")
Data.head()

Data_pakai = Data
DateTime = Data_pakai['Date'] + ' ' + Data_pakai['Time']
Data_pakai['DateTime'] = DateTime
Data_pakai = Data_pakai.drop(columns="Date")
Data_pakai = Data_pakai.drop(columns="Time")
Data_pakai = Data_pakai.drop(columns="Device")

Data_pakai

#Check and Plot Data (Hanya Check Doang gak pakal dipakae di preprocessing)
Data_checkz = Data_pakai
Data_checkz = Data_checkz.set_index(pd.to_datetime(Data_checkz["DateTime"], errors='coerce', format = "%Y-%m-%d %H:%M:%S"))

Data_checkz = Data_checkz.drop(['DateTime'], axis=1)

Data_checkz.Kwh.plot(color = "red") 
plt.tight_layout()
plt.show()

"""# Coba Data Baru Pake Volt dan I

"""

Data_pakai



"""# Preprocessing

"""

Data_proses = Data_pakai
Data_dateBenar = pd.to_datetime(Data_proses["DateTime"],format = "%Y-%m-%d %H:%M:%S", errors='coerce')
Data_Benar = pd.concat([Data_dateBenar,Data_proses["Kwh"]], axis=1)

Data_Benar = Data_Benar.dropna()
Data_Benar

Last_Value = Data_Benar["Kwh"].iloc[-1]
final_df = Data_Benar.loc[(Data_Benar["Kwh"] > 0.0)]

final_df

format = '%Y-%m-%d %H:%M:%S'
final_df['Datetime'] = pd.to_datetime(final_df['DateTime'], format=format)
final_df = final_df.set_index(pd.DatetimeIndex(final_df['Datetime']))
final_df

final_df.drop(['DateTime'], axis=1, inplace=True)
final_df.drop(['Datetime'], axis=1, inplace=True)
final_df

df_hour = final_df.resample('30min').max() 
df_hour = df_hour.resample('h').min()

df_hour.Kwh.plot(title='Penggunaan Kwh', color='red') 
plt.tight_layout()
plt.show()

df_interpolate_lin = df_hour.interpolate(method='linear',axis=0)
df_interpolate_lin

df_interpolate_lin.Kwh.plot(title='Penggunaan Kwh', color='red') 
plt.tight_layout()
plt.show()

df_pakai = df_interpolate_lin
df_pakai = df_pakai.iloc[int(np.ceil(len(df_pakai.values)*.30)):]
df_pakai

df_pakai.Kwh.plot(title='Penggunaan Kwh', color='red') 
plt.tight_layout()
plt.show()

"""# Cari Delta

"""

df_pakai

Data_Benar = df_pakai
Data_benar = Data_Benar.loc[(Data_Benar["Kwh"] > 0.0)]
old_kwh = []
old_kwh.append(0)

for kwh in Data_benar['Kwh'].values:
  old_kwh.append(kwh)

old_kwh.pop()
Data_benar['old_kwh'] = old_kwh
Data_benar['delta_kwh'] = Data_benar['Kwh'] - Data_benar['old_kwh']

Data_benar.drop(['old_kwh'], axis=1, inplace=True)
Data_benar

Data_benar_delta = Data_benar.loc[(Data_benar["delta_kwh"] > 0.0)]
Data_benar_delta

sns.scatterplot(x=Data_benar['Kwh'], y=Data_benar['delta_kwh'], data=Data_benar)

Data_benar.delta_kwh.plot(title='Delta Kwh Perjam', color='red') 
Data_benar.Kwh.plot(title='Delta Kwh Perjam', color='blue') 
plt.tight_layout()
plt.show()

"""# Model AHC

"""

Data_benar_delta.drop(['Kwh'], axis=1, inplace=True)
Data_benar_delta.drop(['delta_kwh'], axis=1, inplace=True)
Data_benar_delta

#dendogram
import scipy.cluster.hierarchy as shc
plt.figure(figsize=(20, 10))  
plt.title("Dendrograms")  
dend = shc.dendrogram(shc.linkage(Data_benar_delta, method='complete'))

from sklearn.cluster import AgglomerativeClustering
cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='complete')  
cluster.fit_predict(Data_benar_delta)

from sklearn.cluster import AgglomerativeClustering
import numpy as np
clustering = AgglomerativeClustering().fit(Data_benar_delta)

clustering

clustering.labels_

Data_benar_delta["kluster"] = cluster.fit_predict(Data_benar_delta)
Data_benar_delta

plt.figure(figsize=(10, 10))  
plt.scatter(Data_benar_delta['delta_kwh'],Data_benar_delta['kluster'],c=cluster.labels_) 
plt.xlabel("Kwh") #x label
plt.ylabel("kluster") #y label

import sklearn.metrics
from sklearn.metrics import silhouette_score
silhouette_score(Data_benar_delta,clustering.labels_)